{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9680899-1274-40f1-b16f-b40a9c0ba75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88a50577-5eb6-4421-aec6-b1f4db1878d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define class labels and image size\n",
    "label = ['driving_license', 'social_security', 'others']\n",
    "img_size = 224\n",
    "\n",
    "def get_data(data_dir):\n",
    "    \"\"\"\n",
    "    Reads images from a directory structure with subfolders for each class and resizes them.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): The base directory containing subfolders for each class.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: An array of image data and corresponding class labels.\n",
    "    \"\"\"\n",
    "    data = []  # Initialize an empty list to store image data and labels\n",
    "\n",
    "    for each_label in label:\n",
    "        path = os.path.join(data_dir, each_label)  # Path to the subfolder for each class\n",
    "        class_num = label.index(each_label)  # Get the class label\n",
    "\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                # Read the image in BGR format and convert it to RGB format\n",
    "                img_arr = cv2.imread(os.path.join(path, img))[...,::-1]\n",
    "                \n",
    "                # Resize the image to the preferred size\n",
    "                resized_arr = cv2.resize(img_arr, (img_size, img_size))\n",
    "                \n",
    "                # Append the resized image and its class label to the data list\n",
    "                data.append([resized_arr, class_num])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    \n",
    "    return np.array(data)  # Convert the list of data to a numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45fe6ed6-d150-4d57-b7b9-28777e5cd972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined training data path\n",
    "train = get_data('./Training data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9f509d-9039-4880-8267-373b87140030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Initialize an empty list to store class names\n",
    "l = []\n",
    "\n",
    "# Iterate through the 'train' dataset\n",
    "for i in train:\n",
    "    if i[1] == 0:\n",
    "        l.append(\"driving license\")\n",
    "    elif i[1] == 1:\n",
    "        l.append(\"social security\")\n",
    "    else:\n",
    "        l.append(\"Others\")\n",
    "\n",
    "# Set the style for the Seaborn plot\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "# Create a countplot to visualize the class distribution\n",
    "sns.countplot(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f908f982-59d7-47a5-8cae-7c3bed8bdd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make numpy array of xtrain and y train,normalize it,and reshape to 224*224\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_val = []  \n",
    "y_val = []  \n",
    "\n",
    "for feature, label in train:\n",
    "    x_train.append(feature)\n",
    "    y_train.append(label)\n",
    "\n",
    "# Normalize the data\n",
    "x_train = np.array(x_train) / 255\n",
    "\n",
    "# Reshape the data to the desired shape (assuming grayscale images)\n",
    "x_train = x_train.reshape(-1, img_size, img_size, 1)\n",
    "\n",
    "# Convert y_train to a NumPy array\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Similarly, for validation data (assuming you have a validation dataset 'val')\n",
    "for feature, label in val:  # 'val' should be defined similarly to 'train'\n",
    "    x_val.append(feature)\n",
    "    y_val.append(label)\n",
    "\n",
    "# Normalize the validation data\n",
    "x_val = np.array(x_val) / 255\n",
    "\n",
    "# Reshape the validation data to the desired shape\n",
    "x_val = x_val.reshape(-1, img_size, img_size, 1)\n",
    "\n",
    "# Convert y_val to a NumPy array\n",
    "y_val = np.array(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ddcb1e6-652c-4840-b1da-231f0de9ec53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ImageDataGenerator with specific parameters for data augmentation\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # Set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # Set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # Divide inputs by the standard deviation of the dataset\n",
    "    samplewise_std_normalization=False,  # Divide each input by its standard deviation\n",
    "    zca_whitening=False,  # Apply ZCA whitening\n",
    "    rotation_range=30,  # Randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range=0.2,  # Randomly zoom images\n",
    "    width_shift_range=0.1,  # Randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # Randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    vertical_flip=False  # Randomly flip images vertically (set to False in this case)\n",
    ")\n",
    "\n",
    "# Compute statistics related to data augmentation based on the provided training data\n",
    "datagen.fit(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f38b3bd5-4c79-43b3-9aa5-1e51d25a1f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 112, 112, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 56, 56, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1605760   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 1,644,035\n",
      "Trainable params: 1,644,035\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### Adding sequential model , add a bunch of conv, maxpool, dropout , flatten it and then eventually add a dense of 3 for all 3 classes.\n",
    "\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add a Convolutional layer with 32 filters, 3x3 kernel, \"same\" padding, and ReLU activation\n",
    "model.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\", input_shape=(224, 224, 3))\n",
    "\n",
    "# Add a MaxPooling layer to downsample\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "# Add another Convolutional layer with the same configuration\n",
    "model.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "# Add another MaxPooling layer\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "# Add another Convolutional layer with the same configuration\n",
    "model.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "# Add another MaxPooling layer\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "# Add a Convolutional layer with 64 filters and ReLU activation\n",
    "model.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "# Add a MaxPooling layer\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "# Add a Dropout layer with a dropout rate of 0.4 (40% dropout)\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# Flatten the output\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a Dense layer with 128 units and ReLU activation\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "\n",
    "# Add the final Dense layer with 3 units for the 3 output classes and a softmax activation\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "# Display a summary of the model architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e83b15e-cbb1-4a19-a865-147841121bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer with a learning rate of 0.000001\n",
    "opt = Adam(learning_rate=0.000001)\n",
    "\n",
    "# Compile the model with the specified optimizer, loss function, and metrics\n",
    "model.compile(optimizer=opt, \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bec3bcb7-0c45-4c93-bc7e-00e7a9a321f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "19/19 [==============================] - 39s 2s/step - loss: 1.1004 - accuracy: 0.3283\n",
      "Epoch 2/200\n",
      "19/19 [==============================] - 38s 2s/step - loss: 1.0982 - accuracy: 0.3400\n",
      "Epoch 3/200\n",
      "19/19 [==============================] - 15s 764ms/step - loss: 1.0984 - accuracy: 0.3517\n",
      "Epoch 4/200\n",
      "19/19 [==============================] - 12s 642ms/step - loss: 1.0978 - accuracy: 0.3600\n",
      "Epoch 5/200\n",
      "19/19 [==============================] - 12s 646ms/step - loss: 1.0985 - accuracy: 0.3300\n",
      "Epoch 6/200\n",
      "19/19 [==============================] - 12s 651ms/step - loss: 1.0970 - accuracy: 0.3583\n",
      "Epoch 7/200\n",
      "19/19 [==============================] - 13s 662ms/step - loss: 1.0991 - accuracy: 0.3350\n",
      "Epoch 8/200\n",
      "19/19 [==============================] - 13s 694ms/step - loss: 1.0964 - accuracy: 0.3817\n",
      "Epoch 9/200\n",
      "19/19 [==============================] - 13s 665ms/step - loss: 1.0964 - accuracy: 0.3817\n",
      "Epoch 10/200\n",
      "19/19 [==============================] - 12s 655ms/step - loss: 1.0965 - accuracy: 0.3683\n",
      "Epoch 11/200\n",
      "19/19 [==============================] - 12s 653ms/step - loss: 1.0974 - accuracy: 0.3483\n",
      "Epoch 12/200\n",
      "19/19 [==============================] - 13s 693ms/step - loss: 1.0959 - accuracy: 0.3783\n",
      "Epoch 13/200\n",
      "19/19 [==============================] - 13s 661ms/step - loss: 1.0942 - accuracy: 0.4167\n",
      "Epoch 14/200\n",
      "19/19 [==============================] - 13s 668ms/step - loss: 1.0951 - accuracy: 0.4000\n",
      "Epoch 15/200\n",
      "19/19 [==============================] - 13s 658ms/step - loss: 1.0945 - accuracy: 0.3950\n",
      "Epoch 16/200\n",
      "19/19 [==============================] - 13s 667ms/step - loss: 1.0945 - accuracy: 0.3883\n",
      "Epoch 17/200\n",
      "19/19 [==============================] - 13s 687ms/step - loss: 1.0935 - accuracy: 0.4017\n",
      "Epoch 18/200\n",
      "19/19 [==============================] - 13s 667ms/step - loss: 1.0931 - accuracy: 0.3950\n",
      "Epoch 19/200\n",
      "19/19 [==============================] - 13s 671ms/step - loss: 1.0948 - accuracy: 0.3983\n",
      "Epoch 20/200\n",
      "19/19 [==============================] - 13s 662ms/step - loss: 1.0951 - accuracy: 0.3733\n",
      "Epoch 21/200\n",
      "19/19 [==============================] - 13s 691ms/step - loss: 1.0920 - accuracy: 0.4100\n",
      "Epoch 22/200\n",
      "19/19 [==============================] - 12s 653ms/step - loss: 1.0941 - accuracy: 0.4133\n",
      "Epoch 23/200\n",
      "19/19 [==============================] - 13s 660ms/step - loss: 1.0930 - accuracy: 0.3967\n",
      "Epoch 24/200\n",
      "19/19 [==============================] - 12s 650ms/step - loss: 1.0937 - accuracy: 0.3950\n",
      "Epoch 25/200\n",
      "19/19 [==============================] - 12s 657ms/step - loss: 1.0918 - accuracy: 0.4517\n",
      "Epoch 26/200\n",
      "19/19 [==============================] - 12s 651ms/step - loss: 1.0911 - accuracy: 0.4367\n",
      "Epoch 27/200\n",
      "19/19 [==============================] - 12s 649ms/step - loss: 1.0931 - accuracy: 0.3983\n",
      "Epoch 28/200\n",
      "19/19 [==============================] - 12s 650ms/step - loss: 1.0934 - accuracy: 0.4233\n",
      "Epoch 29/200\n",
      "19/19 [==============================] - 12s 654ms/step - loss: 1.0911 - accuracy: 0.4100\n",
      "Epoch 30/200\n",
      "19/19 [==============================] - 13s 682ms/step - loss: 1.0916 - accuracy: 0.4417\n",
      "Epoch 31/200\n",
      "19/19 [==============================] - 13s 661ms/step - loss: 1.0917 - accuracy: 0.4200\n",
      "Epoch 32/200\n",
      "19/19 [==============================] - 12s 648ms/step - loss: 1.0918 - accuracy: 0.4133\n",
      "Epoch 33/200\n",
      "19/19 [==============================] - 12s 655ms/step - loss: 1.0881 - accuracy: 0.4617\n",
      "Epoch 34/200\n",
      "19/19 [==============================] - 12s 657ms/step - loss: 1.0898 - accuracy: 0.4617\n",
      "Epoch 35/200\n",
      "19/19 [==============================] - 14s 716ms/step - loss: 1.0889 - accuracy: 0.4600\n",
      "Epoch 36/200\n",
      "19/19 [==============================] - 13s 659ms/step - loss: 1.0875 - accuracy: 0.4767\n",
      "Epoch 37/200\n",
      "19/19 [==============================] - 12s 648ms/step - loss: 1.0903 - accuracy: 0.4367\n",
      "Epoch 38/200\n",
      "19/19 [==============================] - 13s 682ms/step - loss: 1.0880 - accuracy: 0.4717\n",
      "Epoch 39/200\n",
      "19/19 [==============================] - 13s 662ms/step - loss: 1.0881 - accuracy: 0.4567\n",
      "Epoch 40/200\n",
      "19/19 [==============================] - 13s 659ms/step - loss: 1.0885 - accuracy: 0.4600\n",
      "Epoch 41/200\n",
      "19/19 [==============================] - 12s 657ms/step - loss: 1.0866 - accuracy: 0.4867\n",
      "Epoch 42/200\n",
      "19/19 [==============================] - 13s 659ms/step - loss: 1.0848 - accuracy: 0.5000\n",
      "Epoch 43/200\n",
      "19/19 [==============================] - 13s 663ms/step - loss: 1.0841 - accuracy: 0.4967\n",
      "Epoch 44/200\n",
      "19/19 [==============================] - 13s 696ms/step - loss: 1.0869 - accuracy: 0.4483\n",
      "Epoch 45/200\n",
      "19/19 [==============================] - 13s 668ms/step - loss: 1.0855 - accuracy: 0.4967\n",
      "Epoch 46/200\n",
      "19/19 [==============================] - 12s 657ms/step - loss: 1.0837 - accuracy: 0.5000\n",
      "Epoch 47/200\n",
      "19/19 [==============================] - 13s 659ms/step - loss: 1.0831 - accuracy: 0.5083\n",
      "Epoch 48/200\n",
      "19/19 [==============================] - 13s 684ms/step - loss: 1.0810 - accuracy: 0.5350\n",
      "Epoch 49/200\n",
      "19/19 [==============================] - 13s 659ms/step - loss: 1.0827 - accuracy: 0.5183\n",
      "Epoch 50/200\n",
      "19/19 [==============================] - 13s 661ms/step - loss: 1.0813 - accuracy: 0.5017\n",
      "Epoch 51/200\n",
      "19/19 [==============================] - 13s 662ms/step - loss: 1.0815 - accuracy: 0.5383\n",
      "Epoch 52/200\n",
      "19/19 [==============================] - 13s 671ms/step - loss: 1.0792 - accuracy: 0.5283\n",
      "Epoch 53/200\n",
      "19/19 [==============================] - 13s 698ms/step - loss: 1.0788 - accuracy: 0.5583\n",
      "Epoch 54/200\n",
      "19/19 [==============================] - 13s 663ms/step - loss: 1.0790 - accuracy: 0.5533\n",
      "Epoch 55/200\n",
      "19/19 [==============================] - 12s 651ms/step - loss: 1.0785 - accuracy: 0.5367\n",
      "Epoch 56/200\n",
      "19/19 [==============================] - 12s 653ms/step - loss: 1.0782 - accuracy: 0.5683\n",
      "Epoch 57/200\n",
      "19/19 [==============================] - 13s 663ms/step - loss: 1.0769 - accuracy: 0.5367\n",
      "Epoch 58/200\n",
      "19/19 [==============================] - 13s 660ms/step - loss: 1.0751 - accuracy: 0.5700\n",
      "Epoch 59/200\n",
      "19/19 [==============================] - 13s 660ms/step - loss: 1.0743 - accuracy: 0.5567\n",
      "Epoch 60/200\n",
      "19/19 [==============================] - 12s 658ms/step - loss: 1.0741 - accuracy: 0.5650\n",
      "Epoch 61/200\n",
      "19/19 [==============================] - 13s 664ms/step - loss: 1.0728 - accuracy: 0.5950\n",
      "Epoch 62/200\n",
      "19/19 [==============================] - 13s 699ms/step - loss: 1.0727 - accuracy: 0.6017\n",
      "Epoch 63/200\n",
      "19/19 [==============================] - 12s 656ms/step - loss: 1.0696 - accuracy: 0.5767\n",
      "Epoch 64/200\n",
      "19/19 [==============================] - 12s 655ms/step - loss: 1.0724 - accuracy: 0.5900\n",
      "Epoch 65/200\n",
      "19/19 [==============================] - 12s 657ms/step - loss: 1.0688 - accuracy: 0.6100\n",
      "Epoch 66/200\n",
      "19/19 [==============================] - 13s 702ms/step - loss: 1.0698 - accuracy: 0.5817\n",
      "Epoch 67/200\n",
      "19/19 [==============================] - 13s 661ms/step - loss: 1.0680 - accuracy: 0.5850\n",
      "Epoch 68/200\n",
      "19/19 [==============================] - 13s 662ms/step - loss: 1.0681 - accuracy: 0.6050\n",
      "Epoch 69/200\n",
      "19/19 [==============================] - 12s 655ms/step - loss: 1.0635 - accuracy: 0.6250\n",
      "Epoch 70/200\n",
      "19/19 [==============================] - 13s 660ms/step - loss: 1.0594 - accuracy: 0.6433\n",
      "Epoch 71/200\n",
      "19/19 [==============================] - 13s 658ms/step - loss: 1.0603 - accuracy: 0.6433\n",
      "Epoch 72/200\n",
      "19/19 [==============================] - 13s 658ms/step - loss: 1.0603 - accuracy: 0.6067\n",
      "Epoch 73/200\n",
      "19/19 [==============================] - 13s 661ms/step - loss: 1.0609 - accuracy: 0.6250\n",
      "Epoch 74/200\n",
      "19/19 [==============================] - 13s 668ms/step - loss: 1.0573 - accuracy: 0.6567\n",
      "Epoch 75/200\n",
      "19/19 [==============================] - 14s 719ms/step - loss: 1.0554 - accuracy: 0.6400\n",
      "Epoch 76/200\n",
      "19/19 [==============================] - 13s 669ms/step - loss: 1.0541 - accuracy: 0.6333\n",
      "Epoch 77/200\n",
      "19/19 [==============================] - 13s 690ms/step - loss: 1.0542 - accuracy: 0.6467\n",
      "Epoch 78/200\n",
      "19/19 [==============================] - 13s 669ms/step - loss: 1.0531 - accuracy: 0.6333\n",
      "Epoch 79/200\n",
      "19/19 [==============================] - 13s 679ms/step - loss: 1.0502 - accuracy: 0.6467\n",
      "Epoch 80/200\n",
      "19/19 [==============================] - 13s 668ms/step - loss: 1.0454 - accuracy: 0.6283\n",
      "Epoch 81/200\n",
      "19/19 [==============================] - 12s 652ms/step - loss: 1.0485 - accuracy: 0.6183\n",
      "Epoch 82/200\n",
      "19/19 [==============================] - 12s 655ms/step - loss: 1.0450 - accuracy: 0.6633\n",
      "Epoch 83/200\n",
      "19/19 [==============================] - 13s 658ms/step - loss: 1.0479 - accuracy: 0.6567\n",
      "Epoch 84/200\n",
      "19/19 [==============================] - 13s 703ms/step - loss: 1.0419 - accuracy: 0.6433\n",
      "Epoch 85/200\n",
      "19/19 [==============================] - 12s 657ms/step - loss: 1.0397 - accuracy: 0.6667\n",
      "Epoch 86/200\n",
      "19/19 [==============================] - 12s 652ms/step - loss: 1.0409 - accuracy: 0.6617\n",
      "Epoch 87/200\n",
      "19/19 [==============================] - 12s 653ms/step - loss: 1.0342 - accuracy: 0.7033\n",
      "Epoch 88/200\n",
      "19/19 [==============================] - 13s 662ms/step - loss: 1.0351 - accuracy: 0.6733\n",
      "Epoch 89/200\n",
      "19/19 [==============================] - 12s 657ms/step - loss: 1.0319 - accuracy: 0.6950\n",
      "Epoch 90/200\n",
      "19/19 [==============================] - 13s 660ms/step - loss: 1.0337 - accuracy: 0.6633\n",
      "Epoch 91/200\n",
      "19/19 [==============================] - 13s 660ms/step - loss: 1.0315 - accuracy: 0.6583\n",
      "Epoch 92/200\n",
      "19/19 [==============================] - 12s 656ms/step - loss: 1.0258 - accuracy: 0.6933\n",
      "Epoch 93/200\n",
      "19/19 [==============================] - 14s 722ms/step - loss: 1.0268 - accuracy: 0.6817\n",
      "Epoch 94/200\n",
      "19/19 [==============================] - 13s 663ms/step - loss: 1.0265 - accuracy: 0.6983\n",
      "Epoch 95/200\n",
      "19/19 [==============================] - 13s 659ms/step - loss: 1.0235 - accuracy: 0.6900\n",
      "Epoch 96/200\n",
      "19/19 [==============================] - 13s 662ms/step - loss: 1.0155 - accuracy: 0.7333\n",
      "Epoch 97/200\n",
      "19/19 [==============================] - 13s 681ms/step - loss: 1.0199 - accuracy: 0.6950\n",
      "Epoch 98/200\n",
      "19/19 [==============================] - 13s 668ms/step - loss: 1.0169 - accuracy: 0.6967\n",
      "Epoch 99/200\n",
      "19/19 [==============================] - 13s 658ms/step - loss: 1.0156 - accuracy: 0.7017\n",
      "Epoch 100/200\n",
      "19/19 [==============================] - 13s 658ms/step - loss: 1.0133 - accuracy: 0.7100\n",
      "Epoch 101/200\n",
      "19/19 [==============================] - 13s 667ms/step - loss: 1.0104 - accuracy: 0.7200\n",
      "Epoch 102/200\n",
      "19/19 [==============================] - 13s 665ms/step - loss: 1.0092 - accuracy: 0.7183\n",
      "Epoch 103/200\n",
      "19/19 [==============================] - 12s 657ms/step - loss: 1.0104 - accuracy: 0.7200\n",
      "Epoch 104/200\n",
      "19/19 [==============================] - 13s 660ms/step - loss: 1.0024 - accuracy: 0.7400\n",
      "Epoch 105/200\n",
      "19/19 [==============================] - 12s 649ms/step - loss: 0.9979 - accuracy: 0.7317\n",
      "Epoch 106/200\n",
      "19/19 [==============================] - 13s 709ms/step - loss: 0.9975 - accuracy: 0.7217\n",
      "Epoch 107/200\n",
      "19/19 [==============================] - 13s 677ms/step - loss: 0.9977 - accuracy: 0.7267\n",
      "Epoch 108/200\n",
      "19/19 [==============================] - 13s 660ms/step - loss: 0.9945 - accuracy: 0.7400\n",
      "Epoch 109/200\n",
      "19/19 [==============================] - 13s 659ms/step - loss: 0.9908 - accuracy: 0.7350\n",
      "Epoch 110/200\n",
      "19/19 [==============================] - 13s 664ms/step - loss: 0.9898 - accuracy: 0.7500\n",
      "Epoch 111/200\n",
      "19/19 [==============================] - 13s 693ms/step - loss: 0.9904 - accuracy: 0.7217\n",
      "Epoch 112/200\n",
      "19/19 [==============================] - 12s 652ms/step - loss: 0.9870 - accuracy: 0.7200\n",
      "Epoch 113/200\n",
      "19/19 [==============================] - 13s 663ms/step - loss: 0.9835 - accuracy: 0.7450\n",
      "Epoch 114/200\n",
      "19/19 [==============================] - 13s 661ms/step - loss: 0.9831 - accuracy: 0.7400\n",
      "Epoch 115/200\n",
      "19/19 [==============================] - 13s 665ms/step - loss: 0.9766 - accuracy: 0.7450\n",
      "Epoch 116/200\n",
      "19/19 [==============================] - 12s 656ms/step - loss: 0.9760 - accuracy: 0.7700\n",
      "Epoch 117/200\n",
      "19/19 [==============================] - 12s 656ms/step - loss: 0.9757 - accuracy: 0.7433\n",
      "Epoch 118/200\n",
      "19/19 [==============================] - 12s 657ms/step - loss: 0.9706 - accuracy: 0.7483\n",
      "Epoch 119/200\n",
      "19/19 [==============================] - 13s 673ms/step - loss: 0.9682 - accuracy: 0.7550\n",
      "Epoch 120/200\n",
      "19/19 [==============================] - 14s 719ms/step - loss: 0.9668 - accuracy: 0.7683\n",
      "Epoch 121/200\n",
      "19/19 [==============================] - 13s 669ms/step - loss: 0.9654 - accuracy: 0.7667\n",
      "Epoch 122/200\n",
      "19/19 [==============================] - 13s 662ms/step - loss: 0.9632 - accuracy: 0.7550\n",
      "Epoch 123/200\n",
      "19/19 [==============================] - 13s 658ms/step - loss: 0.9570 - accuracy: 0.7833\n",
      "Epoch 124/200\n",
      "19/19 [==============================] - 13s 690ms/step - loss: 0.9546 - accuracy: 0.7617\n",
      "Epoch 125/200\n",
      "19/19 [==============================] - 13s 659ms/step - loss: 0.9540 - accuracy: 0.7750\n",
      "Epoch 126/200\n",
      "19/19 [==============================] - 12s 656ms/step - loss: 0.9553 - accuracy: 0.7483\n",
      "Epoch 127/200\n",
      "19/19 [==============================] - 13s 662ms/step - loss: 0.9496 - accuracy: 0.7833\n",
      "Epoch 128/200\n",
      "19/19 [==============================] - 13s 662ms/step - loss: 0.9450 - accuracy: 0.7567\n",
      "Epoch 129/200\n",
      "19/19 [==============================] - 13s 699ms/step - loss: 0.9493 - accuracy: 0.7750\n",
      "Epoch 130/200\n",
      "19/19 [==============================] - 12s 656ms/step - loss: 0.9482 - accuracy: 0.7550\n",
      "Epoch 131/200\n",
      "19/19 [==============================] - 12s 658ms/step - loss: 0.9407 - accuracy: 0.7817\n",
      "Epoch 132/200\n",
      "19/19 [==============================] - 13s 661ms/step - loss: 0.9435 - accuracy: 0.7600\n",
      "Epoch 133/200\n",
      "19/19 [==============================] - 13s 699ms/step - loss: 0.9381 - accuracy: 0.7867\n",
      "Epoch 134/200\n",
      "19/19 [==============================] - 13s 663ms/step - loss: 0.9337 - accuracy: 0.7700\n",
      "Epoch 135/200\n",
      "19/19 [==============================] - 12s 656ms/step - loss: 0.9331 - accuracy: 0.7683\n",
      "Epoch 136/200\n",
      "19/19 [==============================] - 12s 655ms/step - loss: 0.9319 - accuracy: 0.7817\n",
      "Epoch 137/200\n",
      "19/19 [==============================] - 13s 668ms/step - loss: 0.9265 - accuracy: 0.7767\n",
      "Epoch 138/200\n",
      "19/19 [==============================] - 13s 691ms/step - loss: 0.9307 - accuracy: 0.7617\n",
      "Epoch 139/200\n",
      "19/19 [==============================] - 13s 660ms/step - loss: 0.9239 - accuracy: 0.7817\n",
      "Epoch 140/200\n",
      "19/19 [==============================] - 12s 653ms/step - loss: 0.9205 - accuracy: 0.7717\n",
      "Epoch 141/200\n",
      "19/19 [==============================] - 12s 656ms/step - loss: 0.9175 - accuracy: 0.7883\n",
      "Epoch 142/200\n",
      "19/19 [==============================] - 13s 664ms/step - loss: 0.9164 - accuracy: 0.7983\n",
      "Epoch 143/200\n",
      "19/19 [==============================] - 13s 660ms/step - loss: 0.9182 - accuracy: 0.7817\n",
      "Epoch 144/200\n",
      "19/19 [==============================] - 13s 663ms/step - loss: 0.9144 - accuracy: 0.7817\n",
      "Epoch 145/200\n",
      "19/19 [==============================] - 13s 661ms/step - loss: 0.9115 - accuracy: 0.7883\n",
      "Epoch 146/200\n",
      "19/19 [==============================] - 13s 670ms/step - loss: 0.9095 - accuracy: 0.7717\n",
      "Epoch 147/200\n",
      "19/19 [==============================] - 13s 710ms/step - loss: 0.9095 - accuracy: 0.7817\n",
      "Epoch 148/200\n",
      "19/19 [==============================] - 13s 665ms/step - loss: 0.9022 - accuracy: 0.7983\n",
      "Epoch 149/200\n",
      "19/19 [==============================] - 13s 658ms/step - loss: 0.9002 - accuracy: 0.7850\n",
      "Epoch 150/200\n",
      "19/19 [==============================] - 12s 657ms/step - loss: 0.9005 - accuracy: 0.7850\n",
      "Epoch 151/200\n",
      "19/19 [==============================] - 13s 703ms/step - loss: 0.9014 - accuracy: 0.7883\n",
      "Epoch 152/200\n",
      "19/19 [==============================] - 13s 664ms/step - loss: 0.8979 - accuracy: 0.7850\n",
      "Epoch 153/200\n",
      "19/19 [==============================] - 13s 661ms/step - loss: 0.8942 - accuracy: 0.7933\n",
      "Epoch 154/200\n",
      "19/19 [==============================] - 13s 660ms/step - loss: 0.8929 - accuracy: 0.7950\n",
      "Epoch 155/200\n",
      "19/19 [==============================] - 13s 660ms/step - loss: 0.8899 - accuracy: 0.8100\n",
      "Epoch 156/200\n",
      "19/19 [==============================] - 12s 656ms/step - loss: 0.8888 - accuracy: 0.8000\n",
      "Epoch 157/200\n",
      "19/19 [==============================] - 12s 658ms/step - loss: 0.8885 - accuracy: 0.7917\n",
      "Epoch 158/200\n",
      "19/19 [==============================] - 13s 658ms/step - loss: 0.8875 - accuracy: 0.7917\n",
      "Epoch 159/200\n",
      "19/19 [==============================] - 12s 658ms/step - loss: 0.8829 - accuracy: 0.8000\n",
      "Epoch 160/200\n",
      "19/19 [==============================] - 14s 716ms/step - loss: 0.8805 - accuracy: 0.7983\n",
      "Epoch 161/200\n",
      "19/19 [==============================] - 13s 660ms/step - loss: 0.8802 - accuracy: 0.8050\n",
      "Epoch 162/200\n",
      "19/19 [==============================] - 13s 662ms/step - loss: 0.8777 - accuracy: 0.8017\n",
      "Epoch 163/200\n",
      "19/19 [==============================] - 13s 658ms/step - loss: 0.8747 - accuracy: 0.7967\n",
      "Epoch 164/200\n",
      "19/19 [==============================] - 13s 678ms/step - loss: 0.8758 - accuracy: 0.7867\n",
      "Epoch 165/200\n",
      "19/19 [==============================] - 13s 686ms/step - loss: 0.8776 - accuracy: 0.7883\n",
      "Epoch 166/200\n",
      "19/19 [==============================] - 12s 657ms/step - loss: 0.8659 - accuracy: 0.8183\n",
      "Epoch 167/200\n",
      "19/19 [==============================] - 12s 655ms/step - loss: 0.8720 - accuracy: 0.8183\n",
      "Epoch 168/200\n",
      "19/19 [==============================] - 13s 662ms/step - loss: 0.8720 - accuracy: 0.8017\n",
      "Epoch 169/200\n",
      "19/19 [==============================] - 13s 668ms/step - loss: 0.8663 - accuracy: 0.8100\n",
      "Epoch 170/200\n",
      "19/19 [==============================] - 13s 664ms/step - loss: 0.8667 - accuracy: 0.8083\n",
      "Epoch 171/200\n",
      "19/19 [==============================] - 13s 659ms/step - loss: 0.8632 - accuracy: 0.8067\n",
      "Epoch 172/200\n",
      "19/19 [==============================] - 13s 660ms/step - loss: 0.8620 - accuracy: 0.8167\n",
      "Epoch 173/200\n",
      "19/19 [==============================] - 13s 677ms/step - loss: 0.8594 - accuracy: 0.8150\n",
      "Epoch 174/200\n",
      "19/19 [==============================] - 13s 674ms/step - loss: 0.8580 - accuracy: 0.8183\n",
      "Epoch 175/200\n",
      "19/19 [==============================] - 12s 657ms/step - loss: 0.8612 - accuracy: 0.7950\n",
      "Epoch 176/200\n",
      "19/19 [==============================] - 12s 652ms/step - loss: 0.8546 - accuracy: 0.8150\n",
      "Epoch 177/200\n",
      "19/19 [==============================] - 12s 657ms/step - loss: 0.8582 - accuracy: 0.8133\n",
      "Epoch 178/200\n",
      "19/19 [==============================] - 14s 719ms/step - loss: 0.8521 - accuracy: 0.7967\n",
      "Epoch 179/200\n",
      "19/19 [==============================] - 13s 668ms/step - loss: 0.8505 - accuracy: 0.8133\n",
      "Epoch 180/200\n",
      "19/19 [==============================] - 13s 663ms/step - loss: 0.8501 - accuracy: 0.8083\n",
      "Epoch 181/200\n",
      "19/19 [==============================] - 13s 659ms/step - loss: 0.8490 - accuracy: 0.8050\n",
      "Epoch 182/200\n",
      "19/19 [==============================] - 13s 680ms/step - loss: 0.8465 - accuracy: 0.8067\n",
      "Epoch 183/200\n",
      "19/19 [==============================] - 13s 674ms/step - loss: 0.8468 - accuracy: 0.8117\n",
      "Epoch 184/200\n",
      "19/19 [==============================] - 13s 660ms/step - loss: 0.8410 - accuracy: 0.8233\n",
      "Epoch 185/200\n",
      "19/19 [==============================] - 13s 662ms/step - loss: 0.8435 - accuracy: 0.8133\n",
      "Epoch 186/200\n",
      "19/19 [==============================] - 13s 662ms/step - loss: 0.8437 - accuracy: 0.8050\n",
      "Epoch 187/200\n",
      "19/19 [==============================] - 13s 674ms/step - loss: 0.8359 - accuracy: 0.8250\n",
      "Epoch 188/200\n",
      "19/19 [==============================] - 12s 657ms/step - loss: 0.8419 - accuracy: 0.8050\n",
      "Epoch 189/200\n",
      "19/19 [==============================] - 12s 654ms/step - loss: 0.8346 - accuracy: 0.8167\n",
      "Epoch 190/200\n",
      "19/19 [==============================] - 12s 657ms/step - loss: 0.8339 - accuracy: 0.8367\n",
      "Epoch 191/200\n",
      "19/19 [==============================] - 13s 704ms/step - loss: 0.8349 - accuracy: 0.8083\n",
      "Epoch 192/200\n",
      "19/19 [==============================] - 13s 668ms/step - loss: 0.8315 - accuracy: 0.8233\n",
      "Epoch 193/200\n",
      "19/19 [==============================] - 13s 679ms/step - loss: 0.8331 - accuracy: 0.8067\n",
      "Epoch 194/200\n",
      "19/19 [==============================] - 13s 664ms/step - loss: 0.8318 - accuracy: 0.8133\n",
      "Epoch 195/200\n",
      "19/19 [==============================] - 13s 666ms/step - loss: 0.8271 - accuracy: 0.8200\n",
      "Epoch 196/200\n",
      "19/19 [==============================] - 13s 662ms/step - loss: 0.8294 - accuracy: 0.8300\n",
      "Epoch 197/200\n",
      "19/19 [==============================] - 12s 655ms/step - loss: 0.8241 - accuracy: 0.8317\n",
      "Epoch 198/200\n",
      "19/19 [==============================] - 12s 656ms/step - loss: 0.8276 - accuracy: 0.8200\n",
      "Epoch 199/200\n",
      "19/19 [==============================] - 12s 654ms/step - loss: 0.8247 - accuracy: 0.8233\n",
      "Epoch 200/200\n",
      "19/19 [==============================] - 13s 698ms/step - loss: 0.8213 - accuracy: 0.8183\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to the training data for 200 epochs\n",
    "history = model.fit(x_train, y_train, epochs=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd72705b-f8ea-4903-ad0d-5fe6f451672f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0818 21:57:47.380365 140298920219008 deprecation.py:323] From <ipython-input-13-1e233bf338d4>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           precision    recall  f1-score   support\n",
      "\n",
      "driving license (Class 0)       0.82      0.86      0.84       200\n",
      "       pan card (Class 1)       0.89      0.84      0.86       200\n",
      "         Others (Class 2)       0.79      0.79      0.79       200\n",
      "\n",
      "                micro avg       0.83      0.83      0.83       600\n",
      "                macro avg       0.83      0.83      0.83       600\n",
      "             weighted avg       0.83      0.83      0.83       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform inference on the training data (x_train) to make predictions\n",
    "predictions = model.predict_classes(x_train)\n",
    "predictions = predictions.reshape(1, -1)[0]\n",
    "\n",
    "# Print a classification report to evaluate accuracy metrics\n",
    "# Specify the target names for the classes\n",
    "print(classification_report(y_train, predictions, target_names=['driving license (Class 0)', 'pan card (Class 1)', 'Others (Class 2)']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d89aeabf-af6f-4e87-bd8e-0eb5eef8f59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model, including its architecture, weights, and optimizer state.\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9c3c51",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfd5980-85aa-4bd0-94b4-043f725a0807",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
